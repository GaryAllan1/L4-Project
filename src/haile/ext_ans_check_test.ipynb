{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Testing if I can successfully use a simple NLP toolkit to check answers to extended questions where users submit long pieces of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Way using Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.375\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def calculate_similarity(answer1, answer2):\n",
    "    # Tokenize and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens1 = [word.lower() for word in word_tokenize(answer1) if word.isalnum() and word.lower() not in stop_words]\n",
    "    tokens2 = [word.lower() for word in word_tokenize(answer2) if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens1 = [stemmer.stem(token) for token in tokens1]\n",
    "    stemmed_tokens2 = [stemmer.stem(token) for token in tokens2]\n",
    "\n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = set(stemmed_tokens1).intersection(stemmed_tokens2)\n",
    "    union = set(stemmed_tokens1).union(stemmed_tokens2)\n",
    "    similarity = len(intersection) / len(union)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "# Example usage\n",
    "correct_answer = \"Django is a web framework for Python.\"\n",
    "user_answer = \"Python is used to create web applications through the Django framework.\"\n",
    "\n",
    "similarity = calculate_similarity(correct_answer, user_answer)\n",
    "print(f\"Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (User Answer 1): 0.5448623679425841\n",
      "Similarity (User Answer 2): 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalnum() and word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return \" \".join(stemmed_tokens)\n",
    "\n",
    "def calculate_cosine_similarity(answer1, answer2):\n",
    "    # Preprocess the answers\n",
    "    processed_answer1 = preprocess_text(answer1)\n",
    "    processed_answer2 = preprocess_text(answer2)\n",
    "\n",
    "    # Create a CountVectorizer to convert the answers into vectors\n",
    "    vectorizer = CountVectorizer().fit_transform([processed_answer1, processed_answer2])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = cosine_similarity(vectorizer)\n",
    "    similarity = similarity_matrix[0, 1]\n",
    "\n",
    "    return similarity\n",
    "\n",
    "# Example usage\n",
    "correct_answer = \"Divide and Conquer, or sometimes called Divide, Conquer and Combine is a problem solving technique where a problem is firstly divided or broken or decomposed into simpler sub-problems. The sub-problems are then solved independently, often by recursively calling the function to further divide them. Once solved, the sub-problems are combined to solve the original problem.\"\n",
    "user_answer1 = \"a problem-solving strategy that involves breaking down a complex problem into simpler, more manageable subproblems, solving them independently, and then combining their solutions to solve the original problem.\"\n",
    "user_answer2 = \"Django is a framework for developing web applications with Python.\"\n",
    "\n",
    "similarity1 = calculate_cosine_similarity(correct_answer, user_answer1)\n",
    "similarity2 = calculate_cosine_similarity(correct_answer, user_answer2)\n",
    "\n",
    "print(f\"Similarity (User Answer 1): {similarity1}\")\n",
    "print(f\"Similarity (User Answer 2): {similarity2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 5, 7, 10, 13]\n"
     ]
    }
   ],
   "source": [
    "def sort(arr):\n",
    "    for i in range (1, len(arr)):\n",
    "        k = arr[i]\n",
    "        j = i-1\n",
    "        while j >= 0 and k < arr[j]:\n",
    "            arr[j+1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j+1] = k\n",
    "\n",
    "x = [1,5,7,13,4,10]\n",
    "sort(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is going on here?\n",
    "\n",
    "## Preprocessing the text\n",
    "\n",
    "### Tokenizing and removing stop words\n",
    "\n",
    "This breaks the string into a list of words and removes common 'filler words' like a, the, from etc.\n",
    "\n",
    "### Stemming\n",
    "\n",
    "Breaks words down into their base form: chcolatey, chocolates, choco all become chocolate.\n",
    "\n",
    "## Calculating the Similarity\n",
    "\n",
    "I've used cosine similarity. This essentially turns each of the strings into a vector and we calculate the similarity by the cosine angle between these two vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
